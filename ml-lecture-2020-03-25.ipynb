{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Machine Learning (part 2)\n",
    "\n",
    "**BMI 773 Clinical Research Informatics**\n",
    "\n",
    "*Yuriy Sverchkov*\n",
    "\n",
    "*March 25, 2020*\n",
    "\n",
    "[![xkcd: Machine Learning](images/xkcd_machine_learning.png)](https://xkcd.com/1838/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Lecture goals\n",
    "\n",
    "*stretch goals in italics*\n",
    "\n",
    "* Understand concepts\n",
    "  * perceptrons\n",
    "  * hidden units\n",
    "  * multilayer neural networks\n",
    "  * gradient descent\n",
    "  * backpropagation\n",
    "  * activation functions\n",
    "    * sigmoid, hyperbolic tangent, ReLU\n",
    "  * loss functions\n",
    "    * squared error, cross entropy\n",
    "  * logistic regression as a neural network\n",
    "  * input encodings\n",
    "  * output encodings\n",
    "  * *autoencodings*\n",
    "  * *word embeddings*\n",
    "  * *recurrent neural networks*\n",
    "  * *convolutional networks*\n",
    "  * *decision trees*\n",
    "* Pitfalls of machine learning\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Artificial neural networks (ANNs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Artificial neural networks have seen much success in recent years.\n",
    "\n",
    "[find examples]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Biological neurons\n",
    "\n",
    "<table>\n",
    "    <tr>\n",
    "        <td><img src=\"images/neuron.png\"></td>\n",
    "        <td><img src=\"images/all-or-none_law_en.svg\" width=300></td>\n",
    "    </tr>\n",
    "</table>\n",
    "\n",
    "* Receive inputs from other neurons via dendrites\n",
    "* Activate at a certain stimulus threshold\n",
    "* Signal to other neurons via terminal branches"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### An artificial neural network's \"neuron\"\n",
    "\n",
    "<img src='images/artificial-neuron.svg' />\n",
    "\n",
    "$$\n",
    "\\underbrace{y}_\\text{output} =\n",
    "\\sigma\\left( \\overbrace{\n",
    "w_0 + \\sum_{i=1}^m \\underbrace{x_i}_\\text{inputs} w_i\n",
    "}^z \\right) =\n",
    "\\sigma(\n",
    "\\underbrace{\\langle w_0, w_1, w_2, \\ldots, w_m \\rangle}_{\\mathbf w} \\cdot\n",
    "\\underbrace{\\langle 1, x_1, x_2, \\ldots, x_m \\rangle}_{\\mathbf x}\n",
    ")\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Multilayer neural network\n",
    "\n",
    "A typical neural network would have many neurons arranged in many layers\n",
    "\n",
    "<img src='images/lecun-nature-2015-f1c.png' width=600px/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Logistic regression as a neural network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "$$ \\hat y = \\mathrm{expit}(\\beta_0 + \\beta_1 x_1 + \\beta_2 x_2 + \\ldots + \\beta_d x_d) $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "* __Input units:__ $\\langle 1, x_1, x_2, \\ldots, x_d \\rangle$\n",
    "* __Weights:__ $\\langle \\beta_0, \\beta_1, \\beta_2, \\ldots, \\beta_d \\rangle$\n",
    "* __Activation function:__ $\\mathrm{expit}(z) = \\frac{1}{1 + e^{-z}}$\n",
    "* __Output units:__ $\\hat y$\n",
    "* No __hidden units__."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "# insert image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training ANNs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "### How did we train logistic regression?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* We had a training set $(\\mathbf x^{(1)}, y^{(1)}), \\ldots, (\\mathbf x^{(n)}, y^{(n)})$\n",
    "* Our model was a function with parameters $$ f_{LR}(\\boldsymbol \\beta^{(i)}, \\mathbf x^{(i)}) $$\n",
    "* We had an instance-wise cost function (cross-entropy loss) $$\n",
    "\\mathrm{cost}(y, \\hat y) =\n",
    " \\begin{cases}\n",
    "  -\\log( \\hat y ) & \\text{ if }y=1 \\\\\n",
    "  -\\log( 1-\\hat y ) & \\text{ if }y=0\n",
    " \\end{cases} $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training meant finding the parameters that minimize the average cost across all training instances.\n",
    "\n",
    "$$ \\hat{\\boldsymbol \\beta} = \\underset{\\boldsymbol \\beta}{\\arg \\min} \\frac{1}{n} \\sum_{i=1}^n \\mathrm{cost}(y^{(i)}, f_{LR}(\\boldsymbol \\beta, \\mathbf x^{(i)})) $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training ANNs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* training set\n",
    "* model as a function with parameters\n",
    "* cost function -- there are options!\n",
    "* minimize the cost -- how?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cost functions\n",
    "-we saw cross-entropy\n",
    "-squared loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Backpropagation\n",
    "-its how we minimize the cost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ANN as optimization\n",
    "\n",
    "Like with LR, learning an ANN is an optimization task:\n",
    "\n",
    "* cost function\n",
    "\n",
    "### A second look at examples?\n",
    "\n",
    "### (optional) Network architecture tailored to the task\n",
    "\n",
    "* Hierarchical networks\n",
    "* CNN\n",
    "* RNN (very maybe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision trees\n",
    "\n",
    "[image of a decision tree]\n",
    "\n",
    "What is the optimization problem?\n",
    "\n",
    "A greedy optimisation strategy (greedy strategies are not always perfect)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ML pitfalls\n",
    "\n",
    "- A. Bissoto, M. Fornaciali, E. Valle, and S. Avila, “(De)Constructing Bias on Skin Lesion Datasets,” presented at the IEEE Conference on Computer Vision and Pattern Recognition Workshops, 2019, p. 9.\n",
    "- S. G. Finlayson, J. D. Bowers, J. Ito, J. L. Zittrain, A. L. Beam, and I. S. Kohane, “Adversarial attacks on medical machine learning,” Science, vol. 363, no. 6433, pp. 1287–1289, Mar. 2019, doi: 10.1126/science.aaw4399.\n",
    "- R. Caruana, Y. Lou, J. Gehrke, P. Koch, M. Sturm, and N. Elhadad, “Intelligible Models for HealthCare: Predicting Pneumonia Risk and Hospital 30-day Readmission,” in Proceedings of the 21th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining - KDD ’15, Sydney, NSW, Australia, 2015, pp. 1721–1730, doi: 10.1145/2783258.2788613.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "## Image credits in order of appearance\n",
    "\n",
    "* [XKCD](https://xkcd.com/1838/)\n",
    "* [Wikimedia Commons](https://commons.wikimedia.org/wiki/File:All-or-none_law_en.svg)\n",
    "* [Wikimedia Commons (Prof. Loc Vu-Quoc), CC BY-SA 4.0](https://commons.wikimedia.org/w/index.php?curid=72816083)\n",
    "* LeCun et al. Nature 2015"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
